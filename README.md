# 📊 Ridge and Lasso Regression – Practical Implementation

This project demonstrates the practical implementation of **Ridge** and **Lasso** Regression using the **California Housing Dataset**. These regression techniques are used to improve model performance by applying regularization, helping to prevent overfitting and manage multicollinearity.

---

## 📁 Project Structure

- `ridge_lasso.ipynb` – Jupyter Notebook with step-by-step implementation
- `README.md` – Project overview and instructions

---

## 📚 What You’ll Learn

✅ How to:
- Load and explore the California housing dataset  
- Perform Linear, Ridge, and Lasso Regression  
- Use `GridSearchCV` for hyperparameter tuning (alpha)  
- Evaluate model performance using R² score and MSE  
- Visualize residuals using Seaborn KDE plots

---

## 🧰 Technologies Used

- Python
- NumPy
- Pandas
- Matplotlib
- Seaborn
- scikit-learn

---

## 🧪 Model Comparison

| Model             | Regularization | Purpose                     |
|------------------|----------------|-----------------------------|
| Linear Regression| ❌             | Baseline model              |
| Ridge Regression | ✅ (L2)        | Shrinks coefficients        |
| Lasso Regression | ✅ (L1)        | Shrinks & selects features  |

---

## 📈 Evaluation Metrics

- **R² Score**
- **Mean Squared Error**
- **Residual Distribution Plots**

