# ğŸ“Š Ridge and Lasso Regression â€“ Practical Implementation

This project demonstrates the practical implementation of **Ridge** and **Lasso** Regression using the **California Housing Dataset**. These regression techniques are used to improve model performance by applying regularization, helping to prevent overfitting and manage multicollinearity.

---

## ğŸ“ Project Structure

- `ridge_lasso.ipynb` â€“ Jupyter Notebook with step-by-step implementation
- `README.md` â€“ Project overview and instructions

---

## ğŸ“š What Youâ€™ll Learn

âœ… How to:
- Load and explore the California housing dataset  
- Perform Linear, Ridge, and Lasso Regression  
- Use `GridSearchCV` for hyperparameter tuning (alpha)  
- Evaluate model performance using RÂ² score and MSE  
- Visualize residuals using Seaborn KDE plots

---

## ğŸ§° Technologies Used

- Python
- NumPy
- Pandas
- Matplotlib
- Seaborn
- scikit-learn

---

## ğŸ§ª Model Comparison

| Model             | Regularization | Purpose                     |
|------------------|----------------|-----------------------------|
| Linear Regression| âŒ             | Baseline model              |
| Ridge Regression | âœ… (L2)        | Shrinks coefficients        |
| Lasso Regression | âœ… (L1)        | Shrinks & selects features  |

---

## ğŸ“ˆ Evaluation Metrics

- **RÂ² Score**
- **Mean Squared Error**
- **Residual Distribution Plots**

